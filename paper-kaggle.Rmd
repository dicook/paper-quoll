---
title: Kaggle-in-class Data Challenges can Boost Student Learning

# to produce blinded version set to 1
blinded: 0

authors: 
  - name: Julia Polak
    affiliation: Department of Statistics, University of Melbourne
  - name: Dianne Cook
    affiliation: Department of Econometrics and Business Statistics, Monash University

keywords:
- instructional technology
- statistical modeling
- data science
- statistics education
- data mining

abstract: |
  Kaggle is a data modeling competition service, where participants compete to build a model with lower predictive error than other participants. Several years ago they released a reduced service that enables instructors to run competitions in a classroom setting. This paper describes the results of an experiment to determine if the participating in a predictive modeling competition enhances learning. The evidence suggests it does. In addition, students were surveyed to examine if the competition improved engagement and interest in the class.

bibliography: bibliography.bib
output: rticles::asa_article
---

```{r cache=FALSE, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
#packages:
library(knitr)
library(bookdown)
library(knitcitations)
library(RefManageR)
library("tidyverse")
#library("ggpubr")
library("readxl")
library("gridExtra")

knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, kfigr.link=TRUE, kfigr.prefix=TRUE, cache=TRUE, fig.env = TRUE, fig.cap=TRUE, fig.height=3)

options("citation_format" = "pandoc")

BibOptions(check.entries = FALSE, style = "markdown", bib.style = "alphabetic", cite.style = 'alphabetic')
```

# Introduction

Kaggle [@kaggle] is well-known for the data competitions, some richly funded. It provides a platform for predictive modelling and analytics competitions where participants compete to produce the best predictive model for a given data set. In 2015, Kaggle InClass was introduced, as a self-service platform to conduct competitions. These competitions can be private, limited to members of a university course, and are easy to setup. This paper examines the educational benefits of conducting predictive modeling competitions in class on performance, engagement and interest.

# Experimental setup

## Data collection

The experiment was conducted during Fall semester 2017. Data was collected during three classes, one at the University of Melbourne (MAST90083), and two at Monash University (ETC2420/5242 and ETC3250). 

## Competition data

Two data sets were compiled for the kaggle challenges: Melbourne property auction prices and spam classification. The Melbourne auction price data was compiled by extracting information from real estate auction reports (pdf) collected between Feb 2, 2013 and Dec 17, 2016. Students were expected to predict price based on the property characteristics. The spam classificaation data was compiled by graduate students at Iowa State University as part of a statistical computing class by Dr Heike Hofmann, in XXX. Data was compiled by monitoring and extracting information from emails over a period of a week, and manually classifying them as spam or ham. Students were expected to classify the email as spam or not. 

Both data sets provide substantial challenge for prediction.

## Participants

MAST90083 is titled Computational Statistics and Data Mining, is designed for postgraduate level, for students with math, statistics, information technology or actuarial backgrounds. It covers modelling both continuous (regression) and categorical (classification) response variables. The 63 students were randomized into one of two kaggle competitions, one focused on regression (R) and the other classification (C). Students individually built prediction models and made submissions for 16 days, and then were allowed to form groups to compete for another 7 days. 

ETC2420/5242, titled Statistical Thinking, covers regression, and has a mix of undergraduate and postgraduate students. Only the 34 postgraduate students were required to participate in the kaggle competition focused on regression (R). The 145 undergraduate students are considered control for examining performance. The competition ran for one month. Students formed their own teams of 2-4 members to compete. Several undergraduates also chose to compete individually. 

ETC3250, called Business Analytics, is an undergraduate course focusing on data mining. All students participated in a kaggle competition on a classification problem. Because this group had no comparison group, it was difficult to assess performance. This data was primarily used to examine engagement and interest based on a follow-up questionnaire.

<!--
63 enrolled students; postgraduate level; background: math & stats, IT and actuarial science;  

Students were randomly assigned to one of two groups, regression (R) or classification (C). Each group will have a data competition designed for that topic, made available through kaggle in class (https://inclass.kaggle.com). Students wored individually to build predictive models, and submit predictions for the first 16 days. On the 16^{th} day of the competition students received an email that they allowed to establish groups and continue the competition as a group. The competition was continued for additional 7 days. In case they chose to form a group, the final score of the group in total was accounted as their individual mark towards the final grade for the subject and analysed in this project.  Only 3 groups were formed, two groups with 3 students and one group with two students. All other students chose to continue the competition individually.  

Note that the data competition was compulsory to all the students. The volunteering part was the questionnaire at the end of the semester asking for feedback on aspects of the class such as their competition experience, their favourite topic of the semester, and their enjoyment of the material in the subject.
-->

## Platform

MAST90083 used \url{https://inclass.kaggle.com/c/XXX}. ETC2420/5242 used \url{https://inclass.kaggle.com/c/vitticeps}. ETC3250 used \url{https://inclass.kaggle.com/c/XXX}.

# Methodology

## Performance

MAST90083 and ETC2420/5242 included questions on the final exam related to kaggle challenges. Scores for these questions were normalised by the student's total exam score, in order to examine the effect of competition participation on performance. Better performance is equated to better understanding of the material. MAST90083 had the added benefit of multiple part questions with only some parts relating to the competition material. This data was also normalised by question total, to examine understanding in finer detail. ETC2420/5242 covered many topics related to statistical thinking, and included only one of nine questions related to the competition topic.

XXX Can we do % improvement? Need ot be explicit in how the normalisation was conducted. Give formula.

Permutation tests were conducted to examine difference in median scores for students participating or not in a competition. Normalised scores were examined using side-by-side boxplots.  

## Engagement

The students were allowed to submit at most one prediction per day, while the  competition was open. Some students were very engaged in the competition, and took this seriously, competing to get the best model on a daily basis. To examine whether engagement improved performance, exam scores are examined in relation to frequency of submissions during the competition. The variables are shown in a scatterplot, and a linear model was fitted with performance as the response.

## Interest

Students were invited to give feedback about the course, in particular about the data competitions, before the final exam. This information was voluntary, and students who completed the questionnaire were rewarded with a coupon for a free coffee.

# Results

## Performance

Figure \ref{fig:MAST90083} shows the data collected in MAST90083. Normalized scores for the classification and regression questions are plotted as boxplots against type of competition participation. The normalized scores were computed based on overall test score (CE, RE), in plots A, B, as well as by overall question score (CQ, RQ), in plots C, D. The difference in median scores indicates performance improvement. In plot A, the normalized scores for the classification questions were better for students who participated in the classification competition. From plot B, a very small increase in median score on the regression questions can be seen for the students who participated in the regression competition. Plots C, D show the scores normalized by total question score. This increases the difference for the regression performance.

```{r Melb, fig.cap = "\\label{fig:MAST90083} Performance on regression and classification questions relative to total exam score (A, B) and overall question (C, D) for students by type of data competition in MAST90083. Differences in medians indicate improved performance.", fig.height=5, fig.width=6}
library(tidyverse)
library(gridExtra)
library(forcats)
UniMelbData <- read_csv(file="data/deidentified_UMelb.csv") 
UniMelbData <- UniMelbData %>% mutate(Proj_alloc=fct_recode(Proj_alloc, "regression"="Melbourne Price", "classification"="Spam classification"))
g_pte_class <- ggplot(UniMelbData, aes(Proj_alloc, pte_class)) +
  geom_boxplot() + 
  xlab("") + 
  ylab("CE") + 
  annotate("text", x=0.5, y=0.2, label="A") + 
  ggtitle("Classification Performance")
g_pte_reg <- ggplot(UniMelbData, aes(Proj_alloc, pte_reg)) + 
  geom_boxplot() + 
  xlab("") + 
  ylab("RE") + 
  annotate("text", x=0.5, y=0.4, label="B") + 
  ggtitle("Regression Performance")
g_ptq_class <- ggplot(UniMelbData, aes(Proj_alloc, ptq_class)) +
  geom_boxplot() + 
  xlab("Competition") + 
  ylab("CQ") + 
  annotate("text", x=0.5, y=1.0, label="C")
g_ptq_reg <- ggplot(UniMelbData, aes(Proj_alloc, ptq_reg)) + 
  geom_boxplot() + 
  xlab("Competition") + 
  ylab("RQ") + 
  annotate("text", x=0.5, y=1.0, label="D")
grid.arrange(g_pte_class, g_pte_reg, g_ptq_class, g_ptq_reg, ncol=2)
set.seed(88888)
pdif_C <- NULL
for (i in 1:1000) {
  x <- UniMelbData %>% select(Proj_alloc, pte_class)
  x <- x %>% mutate(class = sample(Proj_alloc))
  pdif_C <- c(pdif_C,
            median(x$pte_class[x$class=="classification"]-
                   median(x$pte_class[x$class=="regression"])))
}
dif_C <- median(UniMelbData$pte_class[UniMelbData$Proj_alloc=="classification"]-
       median(UniMelbData$pte_class[UniMelbData$Proj_alloc=="regression"]))
pdif_R <- NULL
for (i in 1:1000) {
  x <- UniMelbData %>% select(Proj_alloc, pte_reg)
  x <- x %>% mutate(class = sample(Proj_alloc))
  pdif_R <- c(pdif_R,
            median(x$pte_reg[x$class=="regression"]-                   median(x$pte_reg[x$class=="classification"])))
}
dif_R <- median(UniMelbData$pte_reg[UniMelbData$Proj_alloc=="regression"]-
       median(UniMelbData$pte_reg[UniMelbData$Proj_alloc=="classification"]))
pdif_CQ <- NULL
for (i in 1:1000) {
  x <- UniMelbData %>% select(Proj_alloc, ptq_class)
  x <- x %>% mutate(class = sample(Proj_alloc))
  pdif_CQ <- c(pdif_CQ,
            median(x$ptq_class[x$class=="classification"]-
            median(x$ptq_class[x$class=="regression"])))
}
dif_CQ <- median(UniMelbData$ptq_class[UniMelbData$Proj_alloc=="classification"]-
       median(UniMelbData$ptq_class[UniMelbData$Proj_alloc=="regression"]))
pdif_RQ <- NULL
for (i in 1:1000) {
  x <- UniMelbData %>% select(Proj_alloc, ptq_reg)
  x <- x %>% mutate(class = sample(Proj_alloc))
  pdif_RQ <- c(pdif_RQ,
            median(x$ptq_reg[x$class=="regression"]-
              median(x$ptq_reg[x$class=="classification"])))
}
dif_RQ <- median(UniMelbData$ptq_reg[UniMelbData$Proj_alloc=="regression"]-
       median(UniMelbData$ptq_reg[UniMelbData$Proj_alloc=="classification"]))
```

Table \ref{tab:Melb_Perm} shows the results of permutation testing of median difference between the groups. Generally the results support the competition improved performance. Students who participated in the kaggle challenge for classification scored `r round(dif_C, 2)` higher than those that did the regression competition, on the classification problem. Using a permutation test, this corresponds to a significant difference in medians, with $p$-value of `r round(length(pdif_C[pdif_C >= dif_C])/1000, 3)`. 

```{r, caption = "\\label{tab:Melb_Perm} Permutation test $p$-values for results from MAST90083, for each of the different normalized scores."}
library(kableExtra)
pvals <- data.frame(cl = c("CE", "RE", "CQ", "RQ"),
  p=c(round(length(pdif_C[pdif_C >= dif_C])/1000, 3),
      round(length(pdif_R[pdif_R >= dif_R])/1000, 3),
      round(length(pdif_CQ[pdif_CQ >= dif_CQ])/1000, 3),
      round(length(pdif_RQ[pdif_RQ >= dif_RQ])/1000, 3)))
kable(t(pvals), row.names=FALSE)
```

Figure \ref{fig:ETC5242} shows the results for students ETC2420/5242. Only the post-graduate students participated in the regression competition, as their additional assessment requirement. Scores for the question on regression in the final exam were compared with the total exam score (RE). The boxplots suggest that the students who participated in the challenge performed relatively better on the regression question than expected given their total exam performance: the median is higher and there is less variability.

```{r ETC5242, fig.cap = "\\label{fig:ETC5242} Performance for regression question relative to total exam score for students who did and didn't do the regression data competition in ETC2420/5242.", fig.width=4, fig.height=3}
scores_5242 <- read_csv("data/deidentified_scores_5242.csv")
scores_2420 <- read_csv("data/deidentified_scores_2420.csv")
#summary(scores_5242$`7b (8)`)
#summary(scores_2420$`7b (8)`)

scores_5242$`Exam Tot` <- apply(scores_5242[,4:27],1, sum, na.rm=T)
scores_2420$`Exam Tot` <- apply(scores_2420[,4:27],1, sum, na.rm=T)

scores_5242 <- scores_5242 %>% mutate(perf = `7b (8)`/`Exam Tot`)
scores_2420 <- scores_2420 %>% mutate(perf = `7b (8)`/`Exam Tot`)
scores_5242 <- scores_5242 %>% mutate(class="Yes") %>%
  filter(!is.na(perf))
scores_2420 <- scores_2420 %>% mutate(class="No") %>%
  filter(!is.na(perf))

#summary(scores_5242$perf)
#summary(scores_2420$perf)
scores <- bind_rows(scores_5242, scores_2420)
ggplot(scores, aes(x=class, y=perf)) + 
  geom_boxplot() + 
  xlab("Participated in competiton") +
  ylab("RE")
```

```{r permtest}
pdif <- NULL
for (i in 1:1000) {
  x <- scores %>% select(class, perf)
  x <- x %>% mutate(class = sample(class))
  pdif <- c(pdif,
            median(x$perf[x$class=="Yes"]-
                   median(x$perf[x$class=="No"])))
}
dif <- median(scores$perf[scores$class=="Yes"]-
       median(scores$perf[scores$class=="No"]))
```

Based on the median, the students who participated in the kaggle challenge scored `r round(dif, 2)` higher than those that didn't, a median of `r round(median(scores$perf[scores$class=="Yes"]), 2)` in comparison to `r round(median(scores$perf[scores$class=="No"]), 2)`. Using a permutation test, this corresponds to a significant difference in medians, with $p$-value of `r round(length(pdif[pdif >= dif])/1000, 3)`. 



## Engagement

The number of submissions that a student made, may be an indicator of performance on the exam questions related to the competition.  A student who is more engaged in the competition may learn more about the material, and consequently perform better on the exam. Figure \ref{fig:numsubmition} shows normalized scores and overall exam scores, against frequency of prediction submissions for the MAST90083 competitions. 

<!--
To examine the correlation between student’s engagement levels and the performances in the exam we plot the number of submission during the competition versus the performances in the exam, Figure \ref{fig:numsubmition}. Once again we exam the performances based on two normalizations. Once normalizing by the total possible marks for the relevant cluster of questions ($PTQ$) and once normalizing by total exam marks ($PTE$). For the students participated in the Melbourne Price competition is the cluster of regression questions. For the students participated in the Spam Classification competition is the cluster of questions about classification methods. 
-->


```{r numsubmition, echo = FALSE, fig.cap = "\\label{fig:numsubmition} Scatterplot of the normalised scores, and exam scores, by number of prediction submissions for MAST90083. " , fig.width=6, fig.height=3}

UniMelbData_long <- UniMelbData %>%
  gather(questype, score, ptq_class, pte_class, ptq_reg, pte_reg) %>%
  separate(questype, c("normtype", "questype")) %>%
  mutate(questype=fct_recode(questype, "classification"="class", "regression"="reg"))
ggplot(filter(UniMelbData_long, normtype=="ptq"), aes(x=numsub, y=score)) + 
  geom_point() + facet_wrap(~questype, ncol=2, scales="free_y") +
  geom_smooth(method="lm", se=FALSE) + 
  ylab("Normalized scores") + 
  xlab("Number of submissions")
```

```{r eval=FALSE}
# Classification: Q1 & Q10 
gsg <- ggplot(UniMelbData %>% filter(Proj_alloc == "Spam classification"), aes(numsub, ptq_class)) + 
  geom_point() + xlab("Num. of submissions") + ylab("")

gse <- ggplot(UniMelbData %>% filter(Proj_alloc == "Spam classification"), aes(numsub, pte_class)) + 
  geom_point() + xlab("Num. of submissions") + ylab("")

grg <- ggplot(UniMelbData %>% filter(Proj_alloc == "Melbourne Price"), aes(numsub, ptq_reg)) + 
  geom_point() + xlab("Num. of submissions") + ylab("")

gre <- ggplot(UniMelbData %>% filter(Proj_alloc == "Melbourne Price"), aes(numsub, pte_reg)) + 
  geom_point() + xlab("Num. of submissions") + ylab("")


pl <- list(grg, gsg,
           gre, gse )


# Create row and column titles
col.titles = c("Question related to project type (PTQ)", "Total exam score (PTE)")
row.titles = c("MElbPrice", "SPAMclass" )

# Add row titles
pl[1:2] = lapply(1:2, function(i) arrangeGrob(pl[[i]], left=row.titles[i]))

# Add column titles and lay out plots
grid.arrange(grobs=lapply(c(1,3), function(i) {
  arrangeGrob(grobs=pl[i:(i+1)], top=col.titles[i/2 + 1], ncol=1)
}), ncol=2)
```

<!--
In Figure \ref{fig:numsubmition} we can clearly see a weak positive correlation between the number of submissions during the data competition and the scores normalized to the total possible marks for the relevant cluster of questions. This suggest that as more engaged the student was with the competition, the question about the methods relevant to her competition were easier to her. There is no correlation between the number of submission and the marks for the relevant cluster of questions normalized by the total exam marks ($PTE$). *BECAUSE … the questions that unrelated to the data competitions (51 points)? students put less effort to learn other material? Harder questions?*


We didn’t found any evidence for correlation between the performances in the competition (final score) and the performances in the exam. This suggest that the single fact of participation improve the students marks in the exam. Not necessarily better students in the competition have grater chances to success in the exam. 
-->


## Interest

# Discussion

This paper has discussed results from an experiment to examine the effectiveness of data competitions on student learning, using Kagggle InClass as the vehicle for conducting the competition. The evidence suggests that participating in competitions enhances learning.  

# Acknowledgments

This project (title: Effect of Data Competition on Learning Experience) has been approved by the Faculty of Science Human Ethics Advisory Group University of Melbourne (ID: 1749858.1 on September 4, 2017) and by Monash University Human Research Ethics Committee (ID: 9985 on August 24, 2017). 

This document was produced in R [@R] with the package knitr [@knitr]. Data cleaning was conducted using tidyr [@tidyr], dplyr [@dplyr] and plots were made with ggplot2 [@ggplot2].

# Supplementary material

The following material is provided in addition to the main paper. 
- Code to reproduce the results is in the Rmd document
- De-identified data 
- Additional details of analysis
- Copies of exam scripts 

